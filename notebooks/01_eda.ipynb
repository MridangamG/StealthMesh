{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "from config import DATA_DIR, DATASET_FILES\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c437c",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc4897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSV files\n",
    "from src.preprocessing.data_loader import DataLoader\n",
    "\n",
    "loader = DataLoader()\n",
    "df = loader.load_all_files()\n",
    "\n",
    "print(f\"\\nDataset loaded: {df.shape[0]:,} rows, {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e71d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info\n",
    "loader.print_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd42f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139883ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names and types\n",
    "print(\"Columns:\")\n",
    "for i, (col, dtype) in enumerate(zip(df.columns, df.dtypes)):\n",
    "    print(f\"{i+1:3}. {col:40} {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49557ea",
   "metadata": {},
   "source": [
    "## 2. Label Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ba521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean labels first\n",
    "df.columns = df.columns.str.strip()\n",
    "df['Label'] = df['Label'].str.strip()\n",
    "\n",
    "# Label distribution\n",
    "label_counts = df['Label'].value_counts()\n",
    "print(\"Label Distribution:\")\n",
    "print(\"=\"*60)\n",
    "for label, count in label_counts.items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"{label:40} {count:>10,} ({pct:6.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7304ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize label distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar plot\n",
    "ax1 = axes[0]\n",
    "colors = ['green' if label == 'BENIGN' else 'red' for label in label_counts.index]\n",
    "bars = ax1.barh(label_counts.index, label_counts.values, color=colors, alpha=0.7)\n",
    "ax1.set_xlabel('Count')\n",
    "ax1.set_title('Label Distribution (Log Scale)')\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "# Add count labels\n",
    "for bar, count in zip(bars, label_counts.values):\n",
    "    ax1.text(count * 1.1, bar.get_y() + bar.get_height()/2, \n",
    "             f'{count:,}', va='center', fontsize=9)\n",
    "\n",
    "# Pie chart (grouped)\n",
    "ax2 = axes[1]\n",
    "benign_count = label_counts.get('BENIGN', 0)\n",
    "attack_count = label_counts.sum() - benign_count\n",
    "sizes = [benign_count, attack_count]\n",
    "labels = ['BENIGN', 'ATTACK']\n",
    "colors = ['green', 'red']\n",
    "explode = (0, 0.05)\n",
    "ax2.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax2.set_title('Binary Classification Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/label_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b6e7b1",
   "metadata": {},
   "source": [
    "## 3. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e5ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Number of numeric features: {len(numeric_cols)}\")\n",
    "\n",
    "# Basic statistics\n",
    "df[numeric_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03159824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "\n",
    "if len(missing) > 0:\n",
    "    print(\"Columns with missing values:\")\n",
    "    for col, count in missing.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"  {col}: {count:,} ({pct:.2f}%)\")\n",
    "else:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10478b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for infinite values\n",
    "inf_counts = {}\n",
    "for col in numeric_cols:\n",
    "    inf_count = np.isinf(df[col]).sum()\n",
    "    if inf_count > 0:\n",
    "        inf_counts[col] = inf_count\n",
    "\n",
    "if inf_counts:\n",
    "    print(\"Columns with infinite values:\")\n",
    "    for col, count in inf_counts.items():\n",
    "        print(f\"  {col}: {count:,}\")\n",
    "else:\n",
    "    print(\"No infinite values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f26cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace inf with nan and fill\n",
    "df_clean = df.replace([np.inf, -np.inf], np.nan)\n",
    "df_clean = df_clean.dropna()\n",
    "print(f\"After cleaning: {len(df_clean):,} rows (removed {len(df) - len(df_clean):,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d099ea",
   "metadata": {},
   "source": [
    "## 4. Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key features to visualize\n",
    "key_features = [\n",
    "    'Flow Duration', \n",
    "    'Total Fwd Packets', \n",
    "    'Total Backward Packets',\n",
    "    'Flow Bytes/s',\n",
    "    'Flow Packets/s',\n",
    "    'Fwd Packet Length Mean'\n",
    "]\n",
    "\n",
    "# Sample for visualization (full data is too large)\n",
    "df_sample = df_clean.sample(n=min(50000, len(df_clean)), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb36b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(key_features):\n",
    "    if feature in df_sample.columns:\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Plot for each class\n",
    "        for label in ['BENIGN', df_sample[df_sample['Label'] != 'BENIGN']['Label'].iloc[0] if len(df_sample[df_sample['Label'] != 'BENIGN']) > 0 else 'Attack']:\n",
    "            if label == 'BENIGN':\n",
    "                data = df_sample[df_sample['Label'] == 'BENIGN'][feature]\n",
    "                color = 'green'\n",
    "            else:\n",
    "                data = df_sample[df_sample['Label'] != 'BENIGN'][feature]\n",
    "                color = 'red'\n",
    "                label = 'Attack'\n",
    "            \n",
    "            # Clip outliers for visualization\n",
    "            data_clipped = data.clip(upper=data.quantile(0.99))\n",
    "            ax.hist(data_clipped, bins=50, alpha=0.5, label=label, color=color, density=True)\n",
    "        \n",
    "        ax.set_title(feature)\n",
    "        ax.set_xlabel('Value')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/feature_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d2acd",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f1b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top features for correlation\n",
    "top_features = [\n",
    "    'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n",
    "    'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
    "    'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean',\n",
    "    'Fwd Packet Length Mean', 'Bwd Packet Length Mean',\n",
    "    'Packet Length Mean', 'Packet Length Std',\n",
    "    'Average Packet Size', 'Init_Win_bytes_forward'\n",
    "]\n",
    "\n",
    "# Filter existing columns\n",
    "existing_features = [f for f in top_features if f in df_sample.columns]\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = df_sample[existing_features].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', \n",
    "            cmap='RdYlBu_r', center=0, square=True,\n",
    "            linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/correlation_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da1d4eb",
   "metadata": {},
   "source": [
    "## 6. Attack Analysis by File/Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafbb0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attacks by source file\n",
    "if 'Source_File' in df.columns:\n",
    "    attack_by_file = df.groupby(['Source_File', 'Label']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    attack_by_file.plot(kind='bar', stacked=True, ax=ax, colormap='tab20')\n",
    "    ax.set_title('Attack Distribution by Source File')\n",
    "    ax.set_xlabel('Source File')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_yscale('log')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/attacks_by_file.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914782bb",
   "metadata": {},
   "source": [
    "## 7. Summary Statistics for StealthMesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07426fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary for paper/research\n",
    "summary = {\n",
    "    'Total Records': len(df),\n",
    "    'Total Features': len(numeric_cols),\n",
    "    'Benign Records': len(df[df['Label'] == 'BENIGN']),\n",
    "    'Attack Records': len(df[df['Label'] != 'BENIGN']),\n",
    "    'Attack Types': df['Label'].nunique() - 1,\n",
    "    'Imbalance Ratio': f\"{len(df[df['Label'] == 'BENIGN']) / len(df[df['Label'] != 'BENIGN']):.2f}:1\"\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET SUMMARY FOR RESEARCH PAPER\")\n",
    "print(\"=\"*60)\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key:25} {value:>20}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6423c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary to file\n",
    "with open('../results/dataset_summary.txt', 'w') as f:\n",
    "    f.write(\"CICIDS 2017 Dataset Summary for StealthMesh\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    for key, value in summary.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "    f.write(\"\\n\\nLabel Distribution:\\n\")\n",
    "    for label, count in label_counts.items():\n",
    "        f.write(f\"  {label}: {count:,}\\n\")\n",
    "\n",
    "print(\"Summary saved to results/dataset_summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f276933",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "Based on this EDA, the next steps for StealthMesh are:\n",
    "\n",
    "1. **Data Preprocessing**: Clean data, handle imbalance, scale features\n",
    "2. **Feature Selection**: Select most important features for lightweight detection\n",
    "3. **Model Training**: Train ML models (RF, XGBoost, Neural Networks)\n",
    "4. **Evaluation**: Test detection accuracy and latency\n",
    "\n",
    "Run the preprocessing pipeline:\n",
    "```bash\n",
    "python preprocess_data.py --classification binary --features 40\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
